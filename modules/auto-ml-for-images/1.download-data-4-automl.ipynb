{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data for Azure Machine Learning AutoML\n",
    "\n",
    "This notebook extracts data from open-images-v7 and send it to an Azure Custom Vision project\n",
    "\n",
    "It assumes you are working with one class only.\n",
    "\n",
    "### Pre-requisites:\n",
    "\n",
    "1. Create a `.env`:\n",
    "\n",
    "```bash\n",
    "cp .env-template .env # copy file\n",
    "```\n",
    "\n",
    "2. Add the required fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erase folder Ëœ/fiftyone/open-images-v7\n",
    "import os\n",
    "os.system('rm -rf ~/fiftyone/open-images-v7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "TargetLabel = \"Coffee cup\"\n",
    "TargetImages = 200\n",
    "\n",
    "try:\n",
    "    # Load the dataset\n",
    "    foz.load_zoo_dataset(\n",
    "        \"open-images-v7\",\n",
    "        split=\"validation\",\n",
    "        label_types=[\"detections\"],\n",
    "        classes=[TargetLabel],\n",
    "        max_samples=TargetImages\n",
    "    )\n",
    "except Exception as e:\n",
    "    # if exception is realted to mongo db, it is ok to proceed\n",
    "    if 'MongoDB' in str(e):\n",
    "        pass\n",
    "    else:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all content of ./data folder\n",
    "os.system('rm -rf ./data')\n",
    "# images are written into ~/fiftyone/open-images-v7/validation . copy them to ./data\n",
    "os.system('cp -r ~/fiftyone/open-images-v7/validation ./data')\n",
    "os.system('ls ./data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using glob read the names of all files under data/data\n",
    "\n",
    "import glob\n",
    "files = glob.glob('./data/data/*')\n",
    "\n",
    "# create a list called files_names with the names of the files, exlucluding the path and the extension\n",
    "# hint: use os.path.basename and os.path.splitext\n",
    "file_names = [os.path.splitext(os.path.basename(f))[0] for f in files]\n",
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read data/metadata/classes.csv into dataframe classes - classes does not have headers. first column is called LabelName, second is called LabelDisplayName\n",
    "classes = pd.read_csv('./data/metadata/classes.csv', header=None, names=['LabelName', 'LabelDisplayName'])\n",
    "\n",
    "# filter classes to only include the class where LabelName is in df.LabelName\n",
    "classes = classes[classes['LabelDisplayName'] == TargetLabel]\n",
    "\n",
    "classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read ./data/labels/detections.csv into a pandas dataframe\n",
    "import pandas as pd\n",
    "\n",
    "detect = pd.read_csv('./data/labels/detections.csv')\n",
    "\n",
    "# keep only rows where LabelName is in classes.LabelName and ImageID is in file_names\n",
    "detect = detect[detect['LabelName'].isin(classes['LabelName']) & detect['ImageID'].isin(file_names)]\n",
    "detect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add two columns: one with the class name and one with the full file path\n",
    "\n",
    "# merge detect with classes on LabelName\n",
    "detect = pd.merge(detect, classes, on='LabelName')\n",
    "\n",
    "# add a column Class with the value in LabelDisplayName\n",
    "detect['Class'] = detect['LabelDisplayName']\n",
    "\n",
    "# add a column Path with the value './data/data/' + ImageID + '.jpg'\n",
    "detect['Path'] = './data/data/' + detect['ImageID'] + '.jpg'\n",
    "\n",
    "detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only Path, Class, XMin\tXMax\tYMin\tYMax\n",
    "detect = detect[['Path', 'Class', 'XMin', 'XMax', 'YMin', 'YMax']]\n",
    "detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Create a dictionary to hold the bounding boxes for each image\n",
    "image_bboxes = defaultdict(list)\n",
    "\n",
    "# Iterate over the rows in the detect dataframe\n",
    "for _, row in detect.iterrows():\n",
    "    image_path = row['Path']\n",
    "    bbox = (row['XMin'], row['XMax'], row['YMin'], row['YMax'])\n",
    "    image_bboxes[image_path].append(bbox)\n",
    "\n",
    "# Convert the dictionary to a list of tuples (image_path, bboxes)\n",
    "merged_bboxes = [(image_path, bboxes) for image_path, bboxes in image_bboxes.items()]\n",
    "merged_bboxes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Rename the folder\n",
    "os.rename('./data/data', './data/images')\n",
    "\n",
    "# Remove other folders from data (anything that is not named \"images\")\n",
    "for item in os.listdir('./data'):\n",
    "    item_path = os.path.join('./data', item)\n",
    "    if item != 'images' and os.path.isdir(item_path):\n",
    "        shutil.rmtree(item_path)\n",
    "\n",
    "# List the contents of the data folder to verify\n",
    "os.listdir('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert merged_bboxes to a DataFrame\n",
    "merged_bboxes_df = pd.DataFrame(merged_bboxes, columns=['Path', 'BBoxes'])\n",
    "\n",
    "# # Save the DataFrame to detections.csv\n",
    "# merged_bboxes_df.to_csv('./data/detections.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create output in format that can be used for automl for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def create_annotations(df, output_file):\n",
    "    # Open the output file in write mode\n",
    "    with open(output_file, 'w') as f:\n",
    "        # Iterate over the rows in the merged_bboxes_df dataframe\n",
    "        for _, row in df.iterrows():\n",
    "            # Create a dictionary for the current image\n",
    "            image_dict = {\n",
    "                \"image_url\": row['Path'].split('/')[-1],\n",
    "                # \"label\": TargetLabel,\n",
    "                \"label\": []\n",
    "            }\n",
    "            \n",
    "            # Iterate over the bounding boxes for the current image\n",
    "            for bbox in row['BBoxes']:\n",
    "                # Create a dictionary for the current bounding box\n",
    "                bbox_dict = {\n",
    "                    \"label\": TargetLabel,\n",
    "                    \"topX\": bbox[0],\n",
    "                    \"topY\": bbox[2],\n",
    "                    \"bottomX\": bbox[1],\n",
    "                    \"bottomY\": bbox[3]\n",
    "                }\n",
    "                # Append the bounding box dictionary to the image dictionary\n",
    "                image_dict[\"label\"].append(bbox_dict)\n",
    "            \n",
    "            # Write the image dictionary as a JSON object to the output file\n",
    "            f.write(json.dumps(image_dict) + '\\n')\n",
    "\n",
    "    # Print the path to the output file\n",
    "    print(f'JSONL file saved to {output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split merged_bbox_df into 3 dataframes: 60% train, 20% validation, 20% test\n",
    "\n",
    "import numpy as np\n",
    "train_df, validation_df, test_df = np.split(merged_bboxes_df.sample(frac=1), [int(.6*len(merged_bboxes_df)), int(.8*len(merged_bboxes_df))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train annotations\n",
    "create_annotations(train_df, './data/train_annotations.jsonl')\n",
    "\n",
    "# Save validation annotations\n",
    "create_annotations(validation_df, './data/validation_annotations.jsonl')\n",
    "\n",
    "# Save test annotations\n",
    "create_annotations(test_df, './data/test_annotations.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
