{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto ML for Images\n",
    "\n",
    "This notebook will show you step by step how to train and deploy an AutoML for images model. \n",
    "\n",
    "We will cover data preparation, model training, evaluation, and deployment. Let's get started!\n",
    "\n",
    "This notebook is based on this [Tutorial: Train an object detection model with AutoML and Python](https://learn.microsoft.com/en-au/azure/machine-learning/tutorial-auto-train-image-models?view=azureml-api-2&tabs=python)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment setup\n",
    "\n",
    "Use Azure Machine learning to track experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"coffee-cup-detection\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image as pil_image\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "def plot_ground_truth_boxes(image_file, ground_truth_boxes):\n",
    "    # Display the image\n",
    "    plt.figure()\n",
    "    img_np = mpimg.imread(image_file)\n",
    "    img = pil_image.fromarray(img_np.astype(\"uint8\"), \"RGB\")\n",
    "    img_w, img_h = img.size\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=(12, 16))\n",
    "    ax.imshow(img_np)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    label_to_color_mapping = {}\n",
    "\n",
    "    print(ground_truth_boxes)\n",
    "\n",
    "    for gt in ground_truth_boxes:\n",
    "        label = gt[\"label\"]\n",
    "\n",
    "        xmin, ymin, xmax, ymax =  gt[\"topX\"], gt[\"topY\"], gt[\"bottomX\"], gt[\"bottomY\"]\n",
    "        topleft_x, topleft_y = img_w * xmin, img_h * ymin\n",
    "        width, height = img_w * (xmax - xmin), img_h * (ymax - ymin)\n",
    "\n",
    "        if label in label_to_color_mapping:\n",
    "            color = label_to_color_mapping[label]\n",
    "        else:\n",
    "            # Generate a random color. If you want to use a specific color, you can use something like \"red\".\n",
    "            color = np.random.rand(3)\n",
    "            label_to_color_mapping[label] = color\n",
    "\n",
    "        # Display bounding box\n",
    "        rect = patches.Rectangle((topleft_x, topleft_y), width, height,\n",
    "                                 linewidth=2, edgecolor=color, facecolor=\"none\")\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Display label\n",
    "        ax.text(topleft_x, topleft_y - 10, label, color=color, fontsize=20)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_ground_truth_boxes_jsonl(image_file, jsonl_file):\n",
    "    image_base_name = os.path.basename(image_file)\n",
    "    ground_truth_data_found = False\n",
    "    with open(jsonl_file) as fp:\n",
    "        for line in fp.readlines():\n",
    "            line_json = json.loads(line)\n",
    "            filename = line_json[\"image_url\"]\n",
    "            if image_base_name in filename:\n",
    "                ground_truth_data_found = True\n",
    "                plot_ground_truth_boxes(image_file, line_json[\"label\"])\n",
    "                break\n",
    "    if not ground_truth_data_found:\n",
    "        print(\"Unable to find ground truth information for image: {}\".format(image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"./data/images/2c359fcd7c83a987.jpg\"\n",
    "jsonl_file = \"./data/train_annotations.jsonl\"\n",
    "\n",
    "plot_ground_truth_boxes_jsonl(image_file, jsonl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-ml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "import json\n",
    "\n",
    "# Load the config.json file\n",
    "with open(\"config.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Authenticate and create MLClient\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=config[\"subscription_id\"],\n",
    "    resource_group_name=config[\"resource_group\"],\n",
    "    workspace_name=config[\"workspace_name\"]\n",
    ")\n",
    "\n",
    "print(\"MLClient created successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading image files by creating a 'data asset URI FOLDER':\n",
    "\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "my_data = Data(\n",
    "    path=\"./data\",\n",
    "    type=AssetTypes.URI_FOLDER,\n",
    "    description=\"Coffee Cup Object detection\",\n",
    "    name=\"coffe-cup-detection\",\n",
    ")\n",
    "\n",
    "uri_folder_data_asset = ml_client.data.create_or_update(my_data)\n",
    "\n",
    "print(uri_folder_data_asset)\n",
    "print(\"\")\n",
    "print(\"Path to folder in Blob Storage:\")\n",
    "print(uri_folder_data_asset.path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edge-microhack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
